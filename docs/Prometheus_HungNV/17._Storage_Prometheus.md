# Storage Prometheus 

## Sử dụng Ram trong prometheus

Prometheus lưu trữ tất cả các mục đang sử dụng trong RAM. Ngoài ra, nó lưu trữ nhiều phần được sử dụng gần đây nhất trong bộ nhớ. Bạn phải cho prometheus biết nó có thể sử dụng bao nhiêu RAM cho bộ nhớ đệm này. 

Cờ `storage.local.target-heap-size` cho phép đặt kich thước mà nó sẽ lưu trữ tối ta trong RAM. Kích thước bộ nhớ RAM vật ký mà Prometheus server sẽ sử dụng là kết quả của các tương tacsc phức tạp giữa `GO runtime` và OS và rất khó để tính toán chính xác. Nên đặt giá trị `storage.local.target-heap-size` không vượt quá 2/3 kích thước RAM.

Ví dụ giá trị `storage.local.target-heap-size` mặc định là 2G và phù hợp với 3G của RAM vật lý. 

## Sử dụng disk

Prometheus lưu trữ time seri database trên disk tại thư mục mặc định là `data`. Cờ `storage.local.retention` cho phép định cấu hình thời gian lưu trữ các metric. 

- Đối với những lần tắt máy bất thường, máy chủ prometheus có thể mất dữ liệu và bộ nhớ có thể ở trạng thái không nhất quán. Prometheus khi khởi động thực hiện khôi phục sự cố. Thông tin về quá trình khôi phục sự cố sẽ được ghi lại, vì vậy bạn có thể sử dụng nó cho công việc forensic nếu cần. Dữ liệu không thể khôi phục được chuyển đến 1 thư mục có tên `orphaned` nằm dưới `storage.local.path`. Hãy xóa dữ liệu đó nếu không cần nữa.

Theo mặc định, các `sample` trong thư mục được nhóm lại với nhau thành 1 hoặc nhiều tệp lên đến 512MB. Khi 1 chuỗi được xóa qua API, các bản ghi xóa được lưu trữ trong các tệp `tombstones`.

Khối hiện tại cho các `sample` đến được lưu trong RAM và không tồn tại hoàn toàn. Nó được bảo vệ khỏi sự cố bằng nhật ký trước (WAL) có thể được phát lại khi máy chủ prometheus khởi động lại . Các tệp lưu trữ trong thư mục WAL trong các phân đoạn 128MB. Prometheus sẽ giữ tối thiểu 3 tệp. Các tệp này là dữ liệu ở dạng raw data chưa được nén nên kích thước của nó có thể sẽ lớn. Các máy chủ có lưu lượng truy cập cao có thể giữ lại nhiều hơn 3 tệp WAL để lưu giữ ít nhất 2 giờ cho dữ liệu ở dạng raw data.

[TSDB format](https://github.com/prometheus/prometheus/blob/release-2.27/tsdb/docs/format/README.md)

- `--storage.tsdb.path`: Nơi Prometheus viết cơ sở dữ liệu của nó. Mặc định là data/.
- `--storage.tsdb.retention.time`: Khi nào thì xóa dữ liệu cũ. Mặc định là 15d. Ghi đè storage.tsdb.retentionnếu cờ này được đặt thành bất kỳ thứ gì khác với mặc định.
- `--storage.tsdb.retention.size`: [EXPERIMENTAL] Số byte khối lưu trữ tối đa cần giữ lại. Dữ liệu cũ nhất sẽ bị xóa trước. Mặc định thành 0hoặc tắt. Cờ này là thử nghiệm và có thể thay đổi trong các bản phát hành trong tương lai. Các đơn vị được hỗ trợ: B, KB, MB, GB, TB, PB, EB. Ví dụ: "512MB"
- `--storage.tsdb.retention`: Không được ủng hộ storage.tsdb.retention.time.
- `--storage.tsdb.wal-compression`: Cho phép nén nhật ký ghi trước (WAL). Tùy thuộc vào dữ liệu của bạn, bạn có thể mong đợi kích thước WAL giảm một nửa mà không cần tải thêm cpu. Cờ này được giới thiệu trong 2.11.0 và được kích hoạt theo mặc định trong 2.20.0. Lưu ý rằng sau khi được kích hoạt, việc hạ cấp Prometheus xuống phiên bản dưới 2.11.0 sẽ yêu cầu xóa WAL.

Prometheus lưu trữ trung bình chỉ 1-2 byte cho mỗi `sample`. Do đó, để lập kế hoạch công suất của máy chủ Prometheus, bạn có thể sử dụng công thức thô:

```
Dung lượng disk cần = Thời gian lưu trữ tính bằng s * Số sample ghi vào mỗi s * dung lượng byte mỗi sample
```

> `Sample` là giá trị duy nhất trong 1 thời điểm trong time seri

## Cài đặt cho nhiều time series

Với cài đặt mặc định `storage.local.target-heap-size` sẽ bị giới hạn trong khoảng `200.000` time seri đồng thời trong bộ nhớ. 

Nếu sử dụng các truy vấn PromQL liên quan đến số lượng time series cao, các flag sau có liên quan:

- `-storage.local.index-cache-size.label-name-to-label-values`: Đối với đối sánh các biểu thức chính quy
- `-storage.local.index-cache-size.label-pair-to-fingerprints`: Tăng kích thước nếu 1 số lượng lớn time serie có cùng 1 label hoặc name. 
- `-storage.local.index-cache-size.fingerprint-to-metric` và `-storage.local.index-cache-size.fingerprint-to-timerange`: Tăng kích thước nếu bạn có 1 số lượng lớn các time seri đã lưu trữ, tức là các chuỗi đã không nhận được mẫu trong 1 thời gian nhưng vẫn chưa đủ cũ để xóa hoàn toàn. 

Nếu một truy vấn chạm đến hơn 100.000 time series, hàng trăm MiB có thể là hợp lý.


